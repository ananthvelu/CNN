{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess training set - Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'data/dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = train_datagen.flow_from_directory(\n",
    "        'data/dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Build CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter = feature detector's matrix size. (its just experimenting number of features..standard is like 32)\n",
    "#colored input shape = 64 x 64 x 3 (3 --> RGB, 3 colors)\n",
    "#black and white input shape = 64 x 64 x 1 (black or white)\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool size matrix square size and strides is how many pixes we want to move or in other words, how the square matrix is traversing in the main feature map\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a second Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter = feature detector's matrix size. (its just experimenting number of features..standard is like 32)\n",
    "#input_shape is same as original or first convolutional layer, and so remove it from here\n",
    "#black and white input shape = 64 x 64 x 1 (black or white)\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Training The CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss= 'binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN on training set and evaluate with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6827 - accuracy: 0.5565\n",
      "Epoch 00001: val_loss improved from inf to 0.63358, saving model to data/cp.ckpt\n",
      "250/250 [==============================] - 40s 160ms/step - loss: 0.6827 - accuracy: 0.5565 - val_loss: 0.6336 - val_accuracy: 0.6420\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.6750\n",
      "Epoch 00002: val_loss improved from 0.63358 to 0.57826, saving model to data/cp.ckpt\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.6081 - accuracy: 0.6750 - val_loss: 0.5783 - val_accuracy: 0.7075\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.7074\n",
      "Epoch 00003: val_loss improved from 0.57826 to 0.55282, saving model to data/cp.ckpt\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.5631 - accuracy: 0.7074 - val_loss: 0.5528 - val_accuracy: 0.7235\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.7335\n",
      "Epoch 00004: val_loss improved from 0.55282 to 0.52083, saving model to data/cp.ckpt\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.5343 - accuracy: 0.7335 - val_loss: 0.5208 - val_accuracy: 0.7450\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.7466\n",
      "Epoch 00005: val_loss improved from 0.52083 to 0.50992, saving model to data/cp.ckpt\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.5134 - accuracy: 0.7466 - val_loss: 0.5099 - val_accuracy: 0.7485\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.7655\n",
      "Epoch 00006: val_loss did not improve from 0.50992\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.4918 - accuracy: 0.7655 - val_loss: 0.5113 - val_accuracy: 0.7505\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.7684\n",
      "Epoch 00007: val_loss improved from 0.50992 to 0.48072, saving model to data/cp.ckpt\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.4720 - accuracy: 0.7684 - val_loss: 0.4807 - val_accuracy: 0.7695\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7874\n",
      "Epoch 00008: val_loss did not improve from 0.48072\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.4540 - accuracy: 0.7874 - val_loss: 0.4827 - val_accuracy: 0.7670\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.7964\n",
      "Epoch 00009: val_loss improved from 0.48072 to 0.46709, saving model to data/cp.ckpt\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.4416 - accuracy: 0.7964 - val_loss: 0.4671 - val_accuracy: 0.7825\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8036\n",
      "Epoch 00010: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.4268 - accuracy: 0.8036 - val_loss: 0.4718 - val_accuracy: 0.7810\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4181 - accuracy: 0.8050\n",
      "Epoch 00011: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.4181 - accuracy: 0.8050 - val_loss: 0.4779 - val_accuracy: 0.7840\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8164\n",
      "Epoch 00012: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.3974 - accuracy: 0.8164 - val_loss: 0.4753 - val_accuracy: 0.7910\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.8235\n",
      "Epoch 00013: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.3899 - accuracy: 0.8235 - val_loss: 0.4928 - val_accuracy: 0.7820\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8255\n",
      "Epoch 00014: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.3829 - accuracy: 0.8255 - val_loss: 0.5136 - val_accuracy: 0.7755\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8311\n",
      "Epoch 00015: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.3732 - accuracy: 0.8311 - val_loss: 0.4694 - val_accuracy: 0.7865\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.8390\n",
      "Epoch 00016: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.3639 - accuracy: 0.8390 - val_loss: 0.5039 - val_accuracy: 0.7735\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3480 - accuracy: 0.8457\n",
      "Epoch 00017: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.3480 - accuracy: 0.8457 - val_loss: 0.4909 - val_accuracy: 0.7790\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3404 - accuracy: 0.8519\n",
      "Epoch 00018: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.3404 - accuracy: 0.8519 - val_loss: 0.4745 - val_accuracy: 0.7975\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8546\n",
      "Epoch 00019: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 34s 134ms/step - loss: 0.3302 - accuracy: 0.8546 - val_loss: 0.4797 - val_accuracy: 0.7880\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.8606\n",
      "Epoch 00020: val_loss did not improve from 0.46709\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.3186 - accuracy: 0.8606 - val_loss: 0.4757 - val_accuracy: 0.7975\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.8661\n",
      "Epoch 00021: val_loss improved from 0.46709 to 0.46499, saving model to data/cp.ckpt\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.3080 - accuracy: 0.8661 - val_loss: 0.4650 - val_accuracy: 0.7960\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.8709\n",
      "Epoch 00022: val_loss did not improve from 0.46499\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.2997 - accuracy: 0.8709 - val_loss: 0.4902 - val_accuracy: 0.7875\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2974 - accuracy: 0.8729\n",
      "Epoch 00023: val_loss did not improve from 0.46499\n",
      "250/250 [==============================] - 34s 135ms/step - loss: 0.2974 - accuracy: 0.8729 - val_loss: 0.4950 - val_accuracy: 0.7910\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.8860\n",
      "Epoch 00024: val_loss did not improve from 0.46499\n",
      "250/250 [==============================] - 34s 134ms/step - loss: 0.2706 - accuracy: 0.8860 - val_loss: 0.5201 - val_accuracy: 0.7780\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.8886\n",
      "Epoch 00025: val_loss did not improve from 0.46499\n",
      "250/250 [==============================] - 34s 134ms/step - loss: 0.2692 - accuracy: 0.8886 - val_loss: 0.5005 - val_accuracy: 0.7890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15a1ad090>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"data/cp.ckpt\"\n",
    "# checkpoint_dir = os.getcwd()\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_best_only=True, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "cnn.fit(x=training_set, validation_data=test_set, epochs=25, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Making A Single Predicton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "single_test = image.load_img('data/dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64, 64))\n",
    "single_test = image.img_to_array(single_test)\n",
    "single_test = np.expand_dims(single_test, axis=0)\n",
    "result = cnn.predict(single_test)\n",
    "\n",
    "# how to know 0 is cat and 1 is dog?\n",
    "print(training_set.class_indices)\n",
    "\n",
    "#first [0] is for batch size\n",
    "#second [0] is prediction array size which is again just 1.\n",
    "if (result[0][0] == 1):\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'Cat'\n",
    "\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "checkpoint_path = \"data/cp.ckpt\"\n",
    "# checkpoint_dir = os.getcwd()\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_best_only=True, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "single_test = image.load_img('data/dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64, 64))\n",
    "single_test = image.img_to_array(single_test)\n",
    "single_test = np.expand_dims(single_test, axis=0)\n",
    "\n",
    "cnn.load_weights(checkpoint_path)\n",
    "result = cnn.predict(single_test)\n",
    "\n",
    "# how to know 0 is cat and 1 is dog?\n",
    "print(training_set.class_indices)\n",
    "\n",
    "#first [0] is for batch size\n",
    "#second [0] is prediction array size which is again just 1.\n",
    "if (result[0][0] == 1):\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'Cat'\n",
    "\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
